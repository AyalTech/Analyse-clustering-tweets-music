{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_key= ''\n",
    "access_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchAndWrite_date_tweets(keyword, lang, count, nameFile, date_since):\n",
    "    tweets = tweepy.Cursor(api.search,\n",
    "                        q=keyword,\n",
    "                        lang=lang,\n",
    "                        since=date_since).items(count)\n",
    "    tweets_arr = []\n",
    "    # Iterate and print tweets\n",
    "    for tweet in tweets:\n",
    "        tweets_arr.append(tweet._json)\n",
    "    \n",
    "    with open(\"../../Data/music/\" + nameFile, \"a\") as output:\n",
    "        output.write(json.dumps(tweets_arr))\n",
    "    return tweets_arr\n",
    "\n",
    "def searchAndWrite_tweets(keyword, lang, count, nameFile):\n",
    "    tweets = tweepy.Cursor(api.search,\n",
    "                        q=keyword,\n",
    "                        lang=lang).items(count)\n",
    "    tweets_arr = []\n",
    "    # Iterate and print tweets\n",
    "    for tweet in tweets:\n",
    "        tweets_arr.append(tweet._json)\n",
    "    \n",
    "    with open(\"../../Data/music/\" + nameFile, \"a\") as output:\n",
    "        output.write(json.dumps(tweets_arr))\n",
    "    return tweets_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_arr_rock_rdm = searchAndWrite_tweets(keyword=\"rock n'roll\", lang=\"en\", count=450, nameFile=\"rock_random.json\")\n",
    "tweets_arr_pop_rdm = searchAndWrite_tweets(keyword=\"pop\", lang=\"en\", count=450, nameFile=\"pop_random.json\")\n",
    "tweets_arr_rap_rdm = searchAndWrite_tweets(keyword=\"rap\", lang=\"en\", count=450, nameFile=\"rap_random.json\")\n",
    "tweets_arr_reggae_rdm = searchAndWrite_tweets(keyword=\"reggae\", lang=\"en\", count=450, nameFile=\"reggae_random.json\")\n",
    "tweets_arr_jazz_rdm = searchAndWrite_tweets(keyword=\"jazz\", lang=\"en\", count=450, nameFile=\"jazz_random.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_arr_rock_since01 = searchAndWrite_date_tweets(keyword=\"rock n'roll\", lang=\"en\", count=450, nameFile=\"rock_since01.json\",date_since=\"2020-05-01\")\n",
    "tweets_arr_pop_since01 = searchAndWrite_date_tweets(keyword=\"pop\", lang=\"en\", count=450, nameFile=\"pop_since01.json\", date_since=\"2020-05-01\")\n",
    "tweets_arr_rap_since01 = searchAndWrite_date_tweets(keyword=\"rap\", lang=\"en\", count=450, nameFile=\"rap_since01.json\")\n",
    "tweets_arr_reggae_since01 = searchAndWrite_date_tweets(keyword=\"reggae\", lang=\"en\", count=450, nameFile=\"reggae_since01.json\")\n",
    "tweets_arr_jazz_since01 = searchAndWrite_date_tweets(keyword=\"jazz\", lang=\"en\", count=450, nameFile=\"jazz_since01.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Data/music/alltype_music_random.json\", \"a\") as output:\n",
    "    output.write(json.dumps(tweets_arr_all_rdm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_arr_final = tweets_arr_all + tweets_arr_all_rdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Data/music/alltype_music.json\", \"a\") as output:\n",
    "    output.write(json.dumps(tweets_arr_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
