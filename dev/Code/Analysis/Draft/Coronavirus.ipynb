{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_key= ''\n",
    "access_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_tweets = \"../Data/covid19/covid19_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchAndWrite_tweets(keyword, lang, count):\n",
    "    tweets = tweepy.Cursor(api.search,\n",
    "                        q=keyword,\n",
    "                        lang=lang).items(count)\n",
    "    tweets_arr = []\n",
    "    # Iterate and print tweets\n",
    "    for tweet in tweets:\n",
    "        tweets_arr.append(tweet._json)\n",
    "    \n",
    "    with open(\"../Data/covid19/data.json\", \"w+\") as output:\n",
    "        output.write(json.dumps(tweets_arr))\n",
    "    return tweets_arr\n",
    "\n",
    "def searchAndWrite_date_tweets(keyword, date_since, lang, count):\n",
    "    tweets = tweepy.Cursor(api.search,\n",
    "                        q=keyword,\n",
    "                        lang=lang,\n",
    "                        since=date_since).items(count)\n",
    "    tweets_arr = []\n",
    "    # Iterate and print tweets\n",
    "    for tweet in tweets:\n",
    "        tweets_arr.append(tweet._json)\n",
    "    \n",
    "    with open(\"../Data/covid19/data.json\", \"w+\") as output:\n",
    "        output.write(json.dumps(tweets_arr))\n",
    "    return tweets_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = [\"#coronavirus\", \"#COVID19\", \"#CoronavirusOutbreak\"]\n",
    "date_since=\"2020-05-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_arr = searchAndWrite_tweets(keyword=search_words, date_since=date_since, lang=\"en\", count=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[tweet['user']['screen_name'],tweet['created_at']] for tweet in tweets_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2320594453bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'screen_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'followers_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'friends_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retweeted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                   tweet['retweet_count'], tweet['user']['location']] for tweet in tweets_arr]\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_arr' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_details = [[tweet['id'], tweet['created_at'], tweet['truncated'], tweet['text'], clean_tweets(p.api.clean(tweet['text'])),\n",
    "                  tweet['user']['screen_name'], tweet['source'],\n",
    "                  tweet['user']['followers_count'], tweet['user']['friends_count'], tweet['retweeted'], \n",
    "                  tweet['retweet_count'], tweet['user']['location']] for tweet in tweets_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(\n",
    "    data=tweet_details, \n",
    "    columns=['id', 'created_at', 'truncated', 'text', 'text_clean', 'screen_name', 'source',\n",
    "             'user_followers_count', 'user_friends_count', 'isRetweeted', 'retweet_count', 'user_location' ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "   return  TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Create a function to get the sentiment\n",
    "def getSentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if (analysis.sentiment[0] > 0):\n",
    "        return 'Positive'\n",
    "    elif (analysis.sentiment[0] < 0):\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Three new columns 'Subjectivity' & 'Polarity' & 'Sentiment'\n",
    "tweets_df['Subjectivity'] = tweets_df['text_clean'].apply(getSubjectivity)\n",
    "tweets_df['Polarity'] = tweets_df['text_clean'].apply(getPolarity)\n",
    "tweets_df['Sentiment'] = tweets_df['text_clean'].apply(getSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total tweets\n",
    "print('Total tweets this period:', len(tweets_df.index), '\\n')\n",
    "\n",
    "# Retweets\n",
    "tweet_df = tweets_df.sort_values(by='isRetweeted', ascending=False)\n",
    "tweet_df = tweet_df.reset_index(drop=True)\n",
    "print('Mean retweets:', round(tweet_df['isRetweeted'].mean(),2), '\\n')\n",
    "print('Top 5 RTed tweets:')\n",
    "print('------------------')\n",
    "for i in range(5):\n",
    "    print(tweet_df['text_clean'].iloc[i], '-', tweet_df['isRetweeted'].iloc[i])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtags & mentions\n",
    "tag_dict = {}\n",
    "mention_dict = {}\n",
    "\n",
    "for i in tweet_df.index:\n",
    "    tweet_text = tweets_df.iloc[i]['text']\n",
    "    tweet = tweet_text.lower()\n",
    "    tweet_tokenized = tweet.split()\n",
    "\n",
    "    for word in tweet_tokenized:\n",
    "        # Hashtags - tokenize and build dict of tag counts\n",
    "        if (word[0:1] == '#' and len(word) > 1):\n",
    "            key = word.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "            if key in tag_dict:\n",
    "                tag_dict[key] += 1\n",
    "            else:\n",
    "                tag_dict[key] = 1\n",
    "\n",
    "        # Mentions - tokenize and build dict of mention counts\n",
    "        if (word[0:1] == '@' and len(word) > 1):\n",
    "            key = word.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "            if key in mention_dict:\n",
    "                mention_dict[key] += 1\n",
    "            else:\n",
    "                mention_dict[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 10 most popular tags and counts\n",
    "top_tags = dict(sorted(tag_dict.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top_tags_sorted = sorted(top_tags.items(), key=lambda x: x[1])[::-1]\n",
    "print('Top 10 hashtags:')\n",
    "print('----------------')\n",
    "for tag in top_tags_sorted:\n",
    "    print(tag[0], '-', str(tag[1]))\n",
    "    \n",
    "# The 10 most popular mentions and counts\n",
    "top_mentions = dict(sorted(mention_dict.items(), key=operator.itemgetter(1), reverse=True)[:10])\n",
    "top_mentions_sorted = sorted(top_mentions.items(), key=lambda x: x[1])[::-1]\n",
    "print('\\nTop 10 mentions:')\n",
    "print('----------------')\n",
    "for mention in top_mentions_sorted:\n",
    "    print(mention[0], '-', str(mention[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "# word cloud visualization\n",
    "allWords = ' '.join([twts for twts in tweets_df['text_clean']])\n",
    "wordCloud = WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(allWords)\n",
    "\n",
    "plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Sentiment analysis\n",
    "plt.figure(figsize=(8,6)) \n",
    "for i in range(0, tweets_df.shape[0]):\n",
    "  plt.scatter(tweets_df[\"Polarity\"][i], tweets_df[\"Subjectivity\"][i], color='Blue') \n",
    "# plt.scatter(x,y,color)   \n",
    "plt.title('Sentiment Analysis') \n",
    "plt.xlabel('Polarity') \n",
    "plt.ylabel('Subjectivity') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage of positive tweets\n",
    "ptweets = tweets_df[tweets_df.Sentiment == 'Positive']\n",
    "ptweets = ptweets['text_clean']\n",
    "ptweets\n",
    "\n",
    "round( (ptweets.shape[0] / tweets_df.shape[0]) * 100 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage of negative tweets\n",
    "ntweets = tweets_df[tweets_df.Sentiment == 'Negative']\n",
    "ntweets = ntweets['text_clean']\n",
    "ntweets\n",
    "\n",
    "round( (ntweets.shape[0] / tweets_df.shape[0]) * 100, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
